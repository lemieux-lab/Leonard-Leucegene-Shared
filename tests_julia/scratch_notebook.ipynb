{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using CSV \n",
    "using DataFrames\n",
    "using Dates\n",
    "using CUDA\n",
    "using Flux\n",
    "using Statistics\n",
    "using Random\n",
    "using ProgressBars\n",
    "using Gadfly\n",
    "using ProgressBars\n",
    "using Cairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"ProgressLogging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15.351611 seconds (41.09 M allocations: 2.115 GiB, 4.87% gc time)\n"
     ]
    }
   ],
   "source": [
    "filename = \"/u/sauves/leucegene-shared/Data/LEUCEGENE/lgn_pronostic_GE_CDS_TPM.csv\"\n",
    "#GE_TRSC_TPM = DataFrame(CSV.File(filename))\n",
    "@time GE_CDS_TPM = CSV.read(filename, DataFrame)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct Data\n",
    "    name::String\n",
    "    data::Array\n",
    "    factor_1::Array\n",
    "    factor_2::Array\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct FoldData \n",
    "    name::String \n",
    "    train::Data\n",
    "    test::Data\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240×979 Matrix{Float64}:\n",
       " 0.0316661   0.378646  0.0616036  0.582353  …  1.53271  1.65251  0.641819\n",
       " 0.607632    0.919941  0.247202   0.825677     1.36331  1.68384  0.747082\n",
       " 0.0542269   0.858341  0.168166   0.353205     1.6256   2.01853  0.638438\n",
       " 0.117943    0.909923  0.458532   0.512683     1.59041  1.44073  0.601077\n",
       " 0.1027      0.92438   0.0417026  0.927698     1.67489  1.70492  0.741999\n",
       " 0.632719    1.1266    0.326749   0.743149  …  2.10699  1.72211  0.669462\n",
       " 0.0639534   0.988574  0.344356   0.509409     1.67006  1.55408  0.53655\n",
       " 0.171966    0.878851  0.411984   0.124825     1.61074  1.58294  0.419827\n",
       " 0.436952    0.956903  0.0219285  0.391883     1.12661  1.48788  0.404533\n",
       " 0.0573734   0.591869  0.0818238  0.454019     1.22687  1.10439  0.251101\n",
       " 0.0553016   0.88431   0.248367   0.115296  …  1.63206  1.31407  0.416914\n",
       " 0.225357    0.899478  0.122377   0.213399     1.86575  1.5498   0.676836\n",
       " 0.972166    1.27069   0.422964   0.571621     1.79595  1.87913  0.586622\n",
       " ⋮                                          ⋱                    \n",
       " 0.307969    1.00438   0.101077   0.141508     1.58703  2.03404  0.713073\n",
       " 0.37873     0.651072  0.670387   0.960123     1.58052  1.4895   0.704171\n",
       " 0.184335    0.979764  0.233056   0.116251  …  1.64031  1.96165  0.594211\n",
       " 0.514918    1.24884   0.652395   1.24805      1.41527  1.83581  0.292348\n",
       " 1.08585     1.04187   0.154558   0.093384     1.49064  1.87974  0.412385\n",
       " 0.310983    0.795254  0.181324   0.642186     1.35096  1.53903  0.64974\n",
       " 0.0242194   0.417911  0.0902978  0.154739     1.4128   1.06721  0.214051\n",
       " 0.293887    1.1168    0.066124   0.689481  …  1.6774   1.87624  0.764609\n",
       " 0.00398708  0.646113  0.0834471  0.139433     1.40485  1.90371  0.487313\n",
       " 1.05421     1.01783   0.854922   0.191943     1.62683  1.86689  0.908436\n",
       " 0.0611097   0.942766  0.433024   0.570145     1.46578  1.67894  0.338197\n",
       " 0.0594044   0.836688  0.458583   0.6198       1.54792  1.99113  0.467873"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = GE_CDS_TPM[:,1]\n",
    "data = GE_CDS_TPM[:,2:end] \n",
    "cols = names(data)\n",
    "# log transforming\n",
    "data = log10.(Array(data) .+ 1)\n",
    "# remove least varying genes\n",
    "ge_var = var(data,dims = 1) \n",
    "ge_var_med = median(ge_var)\n",
    "# high variance only \n",
    "hvg = getindex.(findall(ge_var .> ge_var_med),2)[1:Int(floor(end/10))]\n",
    "data = data[:,hvg]\n",
    "cols = cols[hvg]\n",
    "# verify that the operation worked\n",
    "sum(var(data, dims = 1) .< ge_var_med)\n",
    "# split into train test\n",
    "nsamples = length(index)\n",
    "indices = shuffle(Array{Int}(1:nsamples))\n",
    "nfolds = 5\n",
    "foldsize = Int(nsamples / 5)\n",
    "\n",
    "folds = Array{FoldData}(undef,5)\n",
    "for i in 1:nfolds\n",
    "    tst_idx = indices[(i - 1) * foldsize + 1: i * foldsize]\n",
    "    tr_idx = setdiff(indices, tst_idx)\n",
    "    test = Data(\"test\", data[tst_idx,:], index[tst_idx], cols)\n",
    "    train = Data(\"train\", data[tr_idx,:], index[tr_idx], cols)\n",
    "    fold_data = FoldData(\"fold_$i\", train, test)\n",
    "    folds[i] = fold_data\n",
    "end\n",
    "folds[1].train.factor_1\n",
    "folds[1].train.data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prep_data (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prep_data(data::Data; device = gpu)\n",
    "    ## data preprocessing\n",
    "    ### remove index columns, log transform\n",
    "    n = length(data.factor_1)\n",
    "    m = length(data.factor_2)\n",
    "    values = Array{Float32,2}(undef, (1, n * m))\n",
    "    #print(size(values))\n",
    "    factor_1_index = Array{Int32,1}(undef, n * m)\n",
    "    factor_2_index = Array{Int32,1}(undef, n * m)\n",
    "    # d3_index = Array{Int32,1}(undef, n * m)\n",
    "    for i in 1:n\n",
    "        for j in 1:m\n",
    "            index = (i - 1) * m + j \n",
    "            values[1, index] = data.data[i, j]\n",
    "            factor_1_index[index] = i # Int\n",
    "            factor_2_index[index] = j # Int \n",
    "            # d3_index[index] = data.d3_index[i] # Int \n",
    "        end\n",
    "    end\n",
    "    return (device(factor_1_index), device(factor_2_index)), device(values)\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custom_train! (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function custom_train!(loss, ps, data, opt, loss_data, epoch)\n",
    "    loss_array = Array{Float32,1}(undef, length(data))\n",
    "\n",
    "    for (i, (x, y)) in enumerate(data)\n",
    "        loss_array[i] = loss(x, y)\n",
    "        \n",
    "        gs = gradient(ps) do\n",
    "            loss(x, y)\n",
    "        end\n",
    "        Flux.update!(opt, ps, gs)\n",
    "    end\n",
    "\n",
    "    loss_data[epoch] = mean(loss_array)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nn(factor_1_layer, factor_2_layer, (a, b, c))\n",
    "    return Chain(\n",
    "        Flux.Parallel(vcat, factor_1_layer, factor_2_layer),\n",
    "        Dense(a, b, relu),\n",
    "        Dense(b, c, relu),\n",
    "        Dense(c, 1, identity)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_obtained_expected (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_obtained_expected(X, Y, network, device)\n",
    "    nb = 10000\n",
    "    index = rand(1:length(Y), nb)\n",
    "\n",
    "    obtained = cpu(Y)[index]\n",
    "\n",
    "    X_cpu = cpu(X)\n",
    "    factor_1 = X_cpu[1][index]\n",
    "    factor_2 = X_cpu[2][index]\n",
    "    \n",
    "    expected = cpu(network((device(factor_1), device(factor_2))))\n",
    "\n",
    "    return obtained, expected[1,:]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function plot_accuracy(folder, epoch, obtained, expected)\n",
    "    corP = Statistics.cor(obtained, expected)\n",
    "    draw(\n",
    "        PNG(\"$(folder)/accuracy_at_epoch_$epoch.png\"), \n",
    "        plot(\n",
    "            x=expected, y=obtained, Guide.title(\"Accuracy at epoch $epoch (r = $corP)\"), \n",
    "            Guide.xlabel(\"Expected\"), Guide.ylabel(\"Obtained\"), Geom.abline, \n",
    "            Geom.hexbin(xbincount=100, ybincount=100)\n",
    "        )\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_embeddings (generic function with 2 methods)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_embeddings(dl, X_, Y_, (dims1, dims2), folder, data, epochs = 200; device = gpu)\n",
    "    #prepare outpath\n",
    "    mkdir(\"$(folder)\")\n",
    "    # construct embeddings & the neural net\n",
    "    d1_layer = device(Flux.Embedding(length(data.factor_1), dims1))\n",
    "    d2_layer = device(Flux.Embedding(length(data.factor_2), dims2))\n",
    "    \n",
    "    a = dims1 + dims2 \n",
    "    b = 50\n",
    "    c = 10 \n",
    "\n",
    "    network = device(nn(d1_layer, d2_layer, (a, b, c)))\n",
    "\n",
    "    loss(x, y) = Flux.Losses.mse(network(x), y)\n",
    "    ps = Flux.params(network)\n",
    "    tr = 0.001\n",
    "    opt = Flux.ADAM(tr)\n",
    "\n",
    "    neural_network = (\"- Layer 1 : Embeddings\\n\" * \n",
    "        \"- Layer 2 : Dense($a, $b, relu)\\n\" *\n",
    "        \"- Layer 3 : Dense($b, $c, relu)\\n\" *\n",
    "        \"- Layer 4 : Dense($c, 1, identity)\"\n",
    "    )\n",
    "    println(neural_network)\n",
    "    loss_data = Array{Float32,1}(undef, epochs)\n",
    "    # cycle through epochs\n",
    "    for e in ProgressBar(1:epochs)\n",
    "        custom_train!(loss, ps, dl, opt, loss_data, e)\n",
    "        obtained, expected = get_obtained_expected(X_, Y_, network, device)\n",
    "        #println(iter, \"Prepare intermediate accuracy plot at epoch $(i)...\")\n",
    "        plot_accuracy(folder, e, obtained, expected)\n",
    "        \n",
    "    \n",
    "    end\n",
    "    println(\"final loss: $(loss_data[end])\")\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Layer 1 : Embeddings\n",
      "- Layer 2 : Dense(4, 50, relu)\n",
      "- Layer 3 : Dense(50, 10, relu)\n",
      "- Layer 4 : Dense(10, 1, identity)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%┣                                              ┫ 0/100 [00:00<00:-5, -0s/it]\n",
      "1.0%┣▍                                         ┫ 1/100 [00:00<Inf:Inf, InfGs/it]\n",
      "2.0%┣█                                              ┫ 2/100 [00:00<00:31, 3it/s]\n",
      "3.0%┣█▍                                             ┫ 3/100 [00:00<00:19, 5it/s]\n",
      "4.0%┣█▉                                             ┫ 4/100 [00:00<00:15, 6it/s]\n",
      "5.0%┣██▍                                            ┫ 5/100 [00:01<00:13, 7it/s]\n",
      "6.0%┣██▉                                            ┫ 6/100 [00:01<00:12, 8it/s]\n",
      "7.0%┣███▎                                           ┫ 7/100 [00:01<00:11, 9it/s]\n",
      "8.0%┣███▊                                           ┫ 8/100 [00:01<00:10, 9it/s]\n",
      "9.0%┣████▎                                          ┫ 9/100 [00:01<00:10, 9it/s]\n",
      "10.0%┣████▌                                        ┫ 10/100 [00:01<00:10, 9it/s]\n",
      "11.0%┣█████                                        ┫ 11/100 [00:01<00:09, 9it/s]\n",
      "12.0%┣█████▎                                      ┫ 12/100 [00:01<00:09, 10it/s]\n",
      "13.0%┣█████▊                                      ┫ 13/100 [00:01<00:09, 10it/s]\n",
      "14.0%┣██████▏                                     ┫ 14/100 [00:01<00:09, 10it/s]\n",
      "15.0%┣██████▋                                     ┫ 15/100 [00:01<00:08, 10it/s]\n",
      "16.0%┣███████                                     ┫ 16/100 [00:01<00:08, 10it/s]\n",
      "17.0%┣███████▌                                    ┫ 17/100 [00:02<00:08, 11it/s]\n",
      "18.0%┣████████                                    ┫ 18/100 [00:02<00:08, 10it/s]\n",
      "19.0%┣████████▍                                   ┫ 19/100 [00:02<00:08, 10it/s]\n",
      "20.0%┣████████▉                                   ┫ 20/100 [00:02<00:08, 11it/s]\n",
      "21.0%┣█████████▎                                  ┫ 21/100 [00:02<00:07, 11it/s]\n",
      "22.0%┣█████████▊                                  ┫ 22/100 [00:02<00:07, 11it/s]\n",
      "23.0%┣██████████▏                                 ┫ 23/100 [00:02<00:07, 11it/s]\n",
      "24.0%┣██████████▋                                 ┫ 24/100 [00:02<00:07, 11it/s]\n",
      "25.0%┣███████████                                 ┫ 25/100 [00:02<00:07, 11it/s]\n",
      "26.0%┣███████████▍                                ┫ 26/100 [00:02<00:07, 11it/s]\n",
      "27.0%┣███████████▉                                ┫ 27/100 [00:02<00:07, 11it/s]\n",
      "28.0%┣████████████▎                               ┫ 28/100 [00:02<00:07, 11it/s]\n",
      "29.0%┣████████████▊                               ┫ 29/100 [00:03<00:06, 11it/s]\n",
      "30.0%┣█████████████▏                              ┫ 30/100 [00:03<00:06, 11it/s]\n",
      "31.0%┣█████████████▋                              ┫ 31/100 [00:03<00:06, 11it/s]\n",
      "32.0%┣██████████████                              ┫ 32/100 [00:03<00:06, 11it/s]\n",
      "33.0%┣██████████████▌                             ┫ 33/100 [00:03<00:06, 11it/s]\n",
      "34.0%┣███████████████                             ┫ 34/100 [00:03<00:06, 11it/s]\n",
      "35.0%┣███████████████▍                            ┫ 35/100 [00:03<00:06, 11it/s]\n",
      "36.0%┣███████████████▉                            ┫ 36/100 [00:03<00:06, 11it/s]\n",
      "37.0%┣████████████████▎                           ┫ 37/100 [00:03<00:06, 11it/s]\n",
      "38.0%┣████████████████▊                           ┫ 38/100 [00:03<00:06, 11it/s]\n",
      "39.0%┣█████████████████▏                          ┫ 39/100 [00:03<00:05, 11it/s]\n",
      "40.0%┣█████████████████▋                          ┫ 40/100 [00:03<00:05, 11it/s]\n",
      "41.0%┣██████████████████                          ┫ 41/100 [00:04<00:05, 11it/s]\n",
      "42.0%┣██████████████████▌                         ┫ 42/100 [00:04<00:05, 11it/s]\n",
      "43.0%┣███████████████████                         ┫ 43/100 [00:04<00:05, 11it/s]\n",
      "44.0%┣███████████████████▍                        ┫ 44/100 [00:04<00:05, 11it/s]\n",
      "45.0%┣███████████████████▉                        ┫ 45/100 [00:04<00:05, 11it/s]\n",
      "46.0%┣████████████████████▎                       ┫ 46/100 [00:04<00:05, 11it/s]\n",
      "47.0%┣████████████████████▊                       ┫ 47/100 [00:04<00:05, 11it/s]\n",
      "48.0%┣█████████████████████▏                      ┫ 48/100 [00:04<00:05, 11it/s]\n",
      "49.0%┣█████████████████████▋                      ┫ 49/100 [00:04<00:04, 11it/s]\n",
      "50.0%┣██████████████████████                      ┫ 50/100 [00:04<00:04, 11it/s]\n",
      "51.0%┣██████████████████████▍                     ┫ 51/100 [00:04<00:04, 11it/s]\n",
      "52.0%┣██████████████████████▉                     ┫ 52/100 [00:04<00:04, 11it/s]\n",
      "53.0%┣███████████████████████▎                    ┫ 53/100 [00:05<00:04, 11it/s]\n",
      "54.0%┣███████████████████████▊                    ┫ 54/100 [00:05<00:04, 11it/s]\n",
      "55.0%┣████████████████████████▏                   ┫ 55/100 [00:05<00:04, 12it/s]\n",
      "56.0%┣████████████████████████▋                   ┫ 56/100 [00:05<00:04, 12it/s]\n",
      "57.0%┣█████████████████████████                   ┫ 57/100 [00:05<00:04, 12it/s]\n",
      "58.0%┣█████████████████████████▌                  ┫ 58/100 [00:05<00:04, 11it/s]\n",
      "59.0%┣██████████████████████████                  ┫ 59/100 [00:05<00:04, 12it/s]\n",
      "60.0%┣██████████████████████████▍                 ┫ 60/100 [00:05<00:03, 11it/s]\n",
      "61.0%┣██████████████████████████▉                 ┫ 61/100 [00:05<00:03, 11it/s]\n",
      "62.0%┣███████████████████████████▎                ┫ 62/100 [00:05<00:03, 12it/s]\n",
      "63.0%┣███████████████████████████▊                ┫ 63/100 [00:05<00:03, 12it/s]\n",
      "64.0%┣████████████████████████████▏               ┫ 64/100 [00:05<00:03, 12it/s]\n",
      "65.0%┣████████████████████████████▋               ┫ 65/100 [00:06<00:03, 12it/s]\n",
      "66.0%┣█████████████████████████████               ┫ 66/100 [00:06<00:03, 12it/s]\n",
      "67.0%┣█████████████████████████████▌              ┫ 67/100 [00:06<00:03, 12it/s]\n",
      "68.0%┣██████████████████████████████              ┫ 68/100 [00:06<00:03, 12it/s]\n",
      "69.0%┣██████████████████████████████▍             ┫ 69/100 [00:06<00:03, 12it/s]\n",
      "70.0%┣██████████████████████████████▉             ┫ 70/100 [00:06<00:03, 12it/s]\n",
      "71.0%┣███████████████████████████████▎            ┫ 71/100 [00:06<00:02, 12it/s]\n",
      "72.0%┣███████████████████████████████▊            ┫ 72/100 [00:06<00:02, 12it/s]\n",
      "73.0%┣████████████████████████████████▏           ┫ 73/100 [00:06<00:02, 12it/s]\n",
      "74.0%┣████████████████████████████████▋           ┫ 74/100 [00:06<00:02, 12it/s]\n",
      "75.0%┣█████████████████████████████████           ┫ 75/100 [00:06<00:02, 12it/s]\n",
      "76.0%┣█████████████████████████████████▍          ┫ 76/100 [00:06<00:02, 12it/s]\n",
      "77.0%┣█████████████████████████████████▉          ┫ 77/100 [00:06<00:02, 12it/s]\n",
      "78.0%┣██████████████████████████████████▎         ┫ 78/100 [00:07<00:02, 12it/s]\n",
      "79.0%┣██████████████████████████████████▊         ┫ 79/100 [00:07<00:02, 12it/s]\n",
      "80.0%┣███████████████████████████████████▏        ┫ 80/100 [00:07<00:02, 12it/s]\n",
      "81.0%┣███████████████████████████████████▋        ┫ 81/100 [00:07<00:02, 12it/s]\n",
      "82.0%┣████████████████████████████████████        ┫ 82/100 [00:07<00:02, 12it/s]\n",
      "83.0%┣████████████████████████████████████▌       ┫ 83/100 [00:07<00:01, 12it/s]\n",
      "84.0%┣█████████████████████████████████████       ┫ 84/100 [00:07<00:01, 12it/s]\n",
      "85.0%┣█████████████████████████████████████▍      ┫ 85/100 [00:07<00:01, 12it/s]\n",
      "86.0%┣█████████████████████████████████████▉      ┫ 86/100 [00:07<00:01, 12it/s]\n",
      "87.0%┣██████████████████████████████████████▎     ┫ 87/100 [00:07<00:01, 12it/s]\n",
      "88.0%┣██████████████████████████████████████▊     ┫ 88/100 [00:07<00:01, 12it/s]\n",
      "89.0%┣███████████████████████████████████████▏    ┫ 89/100 [00:07<00:01, 12it/s]\n",
      "90.0%┣███████████████████████████████████████▋    ┫ 90/100 [00:07<00:01, 12it/s]\n",
      "91.0%┣████████████████████████████████████████    ┫ 91/100 [00:07<00:01, 12it/s]\n",
      "92.0%┣████████████████████████████████████████▌   ┫ 92/100 [00:08<00:01, 12it/s]\n",
      "93.0%┣█████████████████████████████████████████   ┫ 93/100 [00:08<00:01, 12it/s]\n",
      "94.0%┣█████████████████████████████████████████▍  ┫ 94/100 [00:08<00:00, 12it/s]\n",
      "95.0%┣█████████████████████████████████████████▉  ┫ 95/100 [00:08<00:00, 12it/s]\n",
      "96.0%┣██████████████████████████████████████████▎ ┫ 96/100 [00:08<00:00, 12it/s]\n",
      "97.0%┣██████████████████████████████████████████▊ ┫ 97/100 [00:08<00:00, 12it/s]\n",
      "98.0%┣███████████████████████████████████████████▏┫ 98/100 [00:08<00:00, 12it/s]\n",
      "99.0%┣███████████████████████████████████████████▋┫ 99/100 [00:08<00:00, 12it/s]\n",
      "\u001b[1A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final loss: 0.08866258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%┣██████████████████████████████████████████┫ 100/100 [00:08<00:00, 12it/s]\n",
      "100.0%┣██████████████████████████████████████████┫ 100/100 [00:08<00:00, 12it/s]\n"
     ]
    }
   ],
   "source": [
    "outpath = \"output\"\n",
    "mb_size = 2 ^ 14\n",
    "fold_data = folds[1]\n",
    "\n",
    "X_tr, Y_tr = prep_data(fold_data.train)\n",
    "train_dl =  Flux.Data.DataLoader((X_tr, Y_tr), batchsize = mb_size)\n",
    "X_tst, Y_tst = prep_data(fold_data.test)\n",
    "test_dl = Flux.Data.DataLoader((X_tst, Y_tst), batchsize = mb_size)\n",
    "\n",
    "train_embeddings(train_dl, X_tr, Y_tr, (2,2), \"$(outpath)/embeddings_$(now())\", fold_data.train, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
